{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2: Object Detection (YOLOv7)\n",
    "\n",
    "In this lab, we'll explore a fascinating use of image classification deep neural networks to peform a different\n",
    "task: object detection.\n",
    "\n",
    "Credits: parts of this lab are based on other authors' code and blog posts:\n",
    "\n",
    "- [YOLO v7 explained](https://blog.roboflow.com/yolov7-breakdown/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv7\n",
    "\n",
    "The YOLO (You Only Look Once) v7 model is the latest in the family of YOLO models released in 2022.\n",
    "\n",
    "The YOLOv7 authors sought to set the state of the art in object detection by creating a network architecture that would predict bounding boxes more accurately than its peers at similar inference speeds.\n",
    "\n",
    "<img src=\"../img/yolov7_eval.png\" title=\"weight\" style=\"width: 600px;\" />\n",
    "\n",
    "In order to achieve these results, the YOLOv7 authors made a number of changes to the YOLO network and training routines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Efficient Layer Aggregation\n",
    "\n",
    "YOLOv7 is built on previous research on this topic, taking into account the amount of memory required to keep layers in memory as well as the distance required for a gradient to back-propagate through the layers. The shorter the gradient, the more powerful their network's learning ability. E-ELAN, an extended version of the ELAN computational block, is the final layer aggregation they select.\n",
    "\n",
    "<img src=\"../img/Efficient_layer_aggregation.png\" title=\"weight\" style=\"width: 600px;\" />\n",
    "\n",
    "\n",
    "### Model Scaling Techniques\n",
    "\n",
    "Object detection models typically take into account the depth of the network, the width of the network, and the resolution on which the network is trained. The authors of YOLOv7 scale the network depth and width simultaneously while concatenating layers together. According to ablation studies, this technique keeps the model architecture optimal while scaling for different sizes.\n",
    "\n",
    "<img src=\"../img/image-37.png\" title=\"weight\" style=\"width: 600px;\" />\n",
    "\n",
    "### Re-parameterization Planning\n",
    "\n",
    "Averaging a set of model weights is used in re-parameterization techniques to create a model that is more robust to the general patterns that it is attempting to model. There has recently been a focus in research on module level re-parameterization, where each component of the network has its own re-parameterization strategy.\n",
    "\n",
    "YOLOv7 uses gradient flow propagation paths to determine which network modules should and should not use re-parameterization strategies.\n",
    "\n",
    "<img src=\"../img/image-38.png\" title=\"weight\" style=\"width: 600px;\" />\n",
    "\n",
    "### Auxiliary Head Coarse-to-Fine\n",
    "\n",
    "The YOLO network head makes the final network predictions, but because it is so far downstream in the network, it may be advantageous to add an auxiliary head somewhere in the middle.\n",
    "\n",
    "Because there is less network between the auxiliary head and the prediction, it does not train as efficiently as the final head, so the YOLOv7 authors experiment with different levels of supervision for this head, settling on a coarse-to-fine definition in which supervision is passed back from the lead head at different granularities.\n",
    "\n",
    "<img src=\"../img/aux_head.png\" title=\"weight\" style=\"width: 600px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLOv7-mask \n",
    "\n",
    "The integration of YOLOv7 with BlendMask is used to perform instance segmentation. Therefore, the YOLOv7 object detection model was fine-tuned on the MS COCO instance segmentation dataset and trained for 30 epochs. It achieves state-of-the-art real-time instance segmentation results.\n",
    "\n",
    "<img src=\"../img/yolov7-mask-architecture.webp\" title=\"weight\" style=\"width: 300px;\" />\n",
    "\n",
    "### YOLOv7-pose \n",
    "\n",
    "The integration of YOLOv7 with YOLO-Pose allows keypoint detection for Pose Estimation. The authors fine-tuned a YOLOv7-W6 people detection model on the MS COCO keypoint detection dataset and achieved state-of-the-art real-time pose estimation performance.\n",
    "\n",
    "<img src=\"../img/yolov7-pose-architecture-259x350.webp\" title=\"weight\" style=\"width: 200px;\" />\n",
    "\n",
    "### Conclusion of performance\n",
    "\n",
    "YOLOv7 significantly improves real-time object detection accuracy while lowering inference costs. As previously demonstrated in the benchmarks, YOLOv7 can effectively reduce about 40% of the parameters and 50% of the computation of state-of-the-art real-time object detections, while achieving faster inference speed and higher detection accuracy.\n",
    "\n",
    "YOLOv7, in general, provides a faster and stronger network architecture with a more effective feature integration method, more accurate object detection performance, a more robust loss function, and increased label assignment and model training efficiency.\n",
    "\n",
    "As a result, YOLOv7 requires significantly less computing power than other deep learning models. Without any pre-trained weights, it can be trained much faster on small datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The YOLOv7 Codebase\n",
    "\n",
    "The Y[OLOv7 GitHub repository](https://github.com/WongKinYiu/yolov7) contains all of the code you need to get started training YOLOv7 on your custom data.\n",
    "\n",
    "You can train the model by use this command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python train.py --workers 8 --device 1 --batch-size 32 --data data/coco.yaml --img 640 640 --cfg cfg/training/yolov7.yaml --weights '' --name yolov7 --hyp data/hyp.scratch.p5.yaml "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv rtml",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
