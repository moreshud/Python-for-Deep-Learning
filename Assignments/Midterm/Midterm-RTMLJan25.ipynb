{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40b7c49b-bcdc-4470-aca5-44a6302450ca",
   "metadata": {},
   "source": [
    "# Midterm Coding - Jan25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee64222-a272-4f07-b8cb-25127e459747",
   "metadata": {},
   "source": [
    "**Question 1)** ResNet on Cifar\n",
    "\n",
    "**Question 2)** ResNet on small dataset\n",
    "\n",
    "**Question 3)** Pretrained ResNet on small dataset\n",
    "\n",
    "**Question 4)** Discussion\n",
    "\n",
    "Please complete the code wherever you see \"#Your code here\"\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc3faa6-293f-4c13-8ba6-1e95def3af12",
   "metadata": {},
   "source": [
    "## Question 1: ResNet on Cifar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f61297-adbb-460e-be80-6cb9a6e0720b",
   "metadata": {},
   "source": [
    "#### 1. Prepare datasets \n",
    "\n",
    "In this part you need to:\n",
    "- transform them to 3x224x224\n",
    "- complete other necessary steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef114ca8-3c95-4ba9-af21-9ffce41b0827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "from copy import copy\n",
    "from copy import deepcopy\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from torchvision import datasets\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6330e09-e90c-4022-b619-aeee5bb583b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Set device to GPU or CPU\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1d3044-c33f-49e4-b1bd-053df548d392",
   "metadata": {},
   "source": [
    "#### Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ea68653-2682-45d5-8c8a-7b6b14d7144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                                  download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f6af40-c6f7-4135-88c0-21a10c3b172c",
   "metadata": {},
   "source": [
    "#### Transform image (augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eee09101-7f4d-494f-bc6e-e22e5ce518f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac34f54-1b6d-439a-af98-83c227bf0856",
   "metadata": {},
   "source": [
    "#### Other necessary steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4710b422-9a87-4ee7-8485-b9ac4d7894af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Train test split + transform (recommend select few e.g. train 40000 val 10000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DataLoaders for the three datasets (recommend bs = 128)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c4b138-7e59-4cdc-8e5c-aefddf347f1e",
   "metadata": {},
   "source": [
    "#### 2. Prepare model \n",
    "\n",
    "In this part you need to:\n",
    "- complete the BottleneckBlock of ResNet\n",
    "- create ResNet50 and ResNet101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa292bb-7443-4803-960d-6aad674ed1f6",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "\n",
    "On page 5 of [the ResNet paper](https://arxiv.org/pdf/1512.03385.pdf), the simplest ResNet\n",
    "described is now known as ResNet18. It is a 1.8 GFLOP CNN with 8 residual blocks (two convolutional\n",
    "layers in each residual block), which along with the initial convolution (7x7 in the paper, 3x3 here)\n",
    "and the final linear / softmax layer gives us 18 layers:\n",
    "\n",
    "<img src=\"img/ResNet18.JPG\" title=\"ResNet18\" style=\"width: 200px;\" />\n",
    "\n",
    "### Residual blocks\n",
    "\n",
    "The residual block is a reusable block.\n",
    "ResNet18 and ResNet34 use very basic residual blocks, but\n",
    "ResNet50, ResNet101, and ResNet152 use more complicated residual blocks\n",
    "with three convolutions, the middle of which is a\n",
    "bottleneck that increases the representational power of the block\n",
    "without an enormous increase in the number of parameters.\n",
    "\n",
    "We need two types of residual block, one that preserves feature map size and one\n",
    "that allows changes to the feature map size:\n",
    "\n",
    "<img src=\"img/residualblock.png\" title=\"Residual block\" style=\"width: 640px;\" />\n",
    "\n",
    "Note that only the shape-preserving residual block has a real identity mapping.\n",
    "The 1x1 strided convolution is the simplest way to allow changes in the input\n",
    "feature map size, but since the parameters are learned, after training, the result\n",
    "may be quite different from an identity mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4929b3b1-2039-4db9-97aa-142e750d0fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    '''\n",
    "    BasicBlock: Simple residual block with two conv layers\n",
    "    '''\n",
    "    EXPANSION = 1\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        # If output size is not equal to input size, reshape it with 1x1 convolution\n",
    "        if stride != 1 or in_planes != out_planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddbc001-8341-4912-b480-e5968d08aee6",
   "metadata": {},
   "source": [
    "Here's the bottlneck version with three layers per residual block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f71fbc9-1d7a-4743-9656-a82a2d179f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckBlock(nn.Module):\n",
    "    '''\n",
    "    BottleneckBlock: More powerful residual block with three convs, used for Resnet50 and up\n",
    "    '''\n",
    "    # Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0932607e-0637-46ae-bfd5-38f21a2931f9",
   "metadata": {},
   "source": [
    "### Resnet\n",
    "\n",
    "Here is the whole shebang for ResNet, with the layer sizes tailored a bit to our input size of 64x64:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f1feeee-654d-491c-9ef4-3654e5acc4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64\n",
    "        # Initial convolution\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        # Residual blocks\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        # FC layer = 1 layer\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = nn.Linear(512 * block.EXPANSION, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.EXPANSION\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee16ca-aa13-4bfa-8196-c33ebcc40888",
   "metadata": {},
   "source": [
    "Create ResNet50 and ResNet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c41e782-9481-4e3e-b078-81ee523a47b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18(num_classes = 10):\n",
    "    '''\n",
    "    First conv layer: 1\n",
    "    4 residual blocks with two sets of two convolutions each: 2*2 + 2*2 + 2*2 + 2*2 = 16 conv layers\n",
    "    last FC layer: 1\n",
    "    Total layers: 1+16+1 = 18\n",
    "    '''\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes)\n",
    "    \n",
    "def ResNet50(num_classes = 10):\n",
    "    # Your code here\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return ResNet(BottleneckBlock, [3, 4, 6, 3], num_classes)\n",
    "    \n",
    "def ResNet101(num_classes = 10):\n",
    "    # Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return ResNet(BottleneckBlock, [3, 4, 23, 3], num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f06f9be-47a9-4169-8c04-0d42d0974ac0",
   "metadata": {},
   "source": [
    "### 3. Training\n",
    "\n",
    "In this part, you need to:\n",
    "- define necessary things for training\n",
    "- train the model\n",
    "- plot training loss and validation accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a417be88-a493-4e19-96de-427accee5451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, weights_name='weight_save', is_inception=False):\n",
    "    '''\n",
    "    train_model: train a model on a dataset\n",
    "    \n",
    "            Parameters:\n",
    "                    model: Pytorch model\n",
    "                    dataloaders: dataset\n",
    "                    criterion: loss function\n",
    "                    optimizer: update weights function\n",
    "                    num_epochs: number of epochs\n",
    "                    weights_name: file name to save weights\n",
    "                    is_inception: The model is inception net (Google LeNet) or not\n",
    "\n",
    "            Returns:\n",
    "                    model: Best model from evaluation result\n",
    "                    val_acc_history: evaluation accuracy history\n",
    "                    loss_acc_history: loss value history\n",
    "    '''\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    loss_acc_history = []\n",
    "\n",
    "    best_model_wts = deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                # for process anything, device and dataset must put in the same place.\n",
    "                # If the model is in GPU, input and output must set to GPU\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                # it uses for update training weights\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        # print('outputs', outputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            epoch_end = time.time()\n",
    "            \n",
    "            elapsed_epoch = epoch_end - epoch_start\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            print(\"Epoch time taken: \", elapsed_epoch)\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), weights_name + \".pth\")\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "            if phase == 'train':\n",
    "                loss_acc_history.append(epoch_loss)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, loss_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb551b73-86c1-429c-b087-b7262deea096",
   "metadata": {},
   "source": [
    "Here we define the model, optimizer, loss function train the model\n",
    "\n",
    "#1252 GB CUDA, Training took around 6-7 mins for me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7337775a-64a9-4669-9a2a-42b95af9ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Model\n",
    "\n",
    "\n",
    "# Loss function\n",
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "# Train model\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a91fe0-8c77-4e8e-9a0f-5bf5de826d28",
   "metadata": {},
   "source": [
    "Please plot training loss and validation accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8de00787-42b4-4b81-b530-8ac5a3a8df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data(val_acc_history, loss_acc_history):\n",
    "     # Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc6e7ab-0bea-4f55-939c-f3c65f4f1e09",
   "metadata": {},
   "source": [
    "### 4. Evaluation\n",
    "\n",
    "In this part, you need to:\n",
    "- define necessary things for evaluating the trained model. This includes function that collects test loss and accuracy\n",
    "- evaluate the model\n",
    "- plot confusion matrix\n",
    "- discuss the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33c1ef6f-1fb6-4f77-9e1a-5d72da7b8f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), predicteds, trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a599b78-b0c5-4949-acdb-8ec45df53455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2d64f01-3a5f-4142-a314-56f75d05a69f",
   "metadata": {},
   "source": [
    "Now, let's take a closer look at the results. Please plot confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f78d2fa-d206-40a1-9645-9085835d978c",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "983913cd-bfb3-4fdc-95dd-1f2e962e2dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(test_true_label_, test_pred_label_):\n",
    "    cm = confusion_matrix(test_true_label_, test_pred_label_)\n",
    "    \n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(10), yticklabels=range(10))\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b47fa-9604-45dd-b48d-e222927dd574",
   "metadata": {},
   "source": [
    "Please discuss the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3cad0e-e565-4838-9cc7-914bc80f508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You discussion here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de58c52c-011b-4d76-8859-7eac9fdba42c",
   "metadata": {},
   "source": [
    "## Question 2: ResNet on small dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba80f4a-36ea-4d3d-b71a-b7524401bc82",
   "metadata": {},
   "source": [
    "In this question, we will train ResNet18 on the Komondor vs. Mop dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da091324-9977-470e-84a0-0d44382588d5",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "481b9603-6087-41b1-916a-d826cf74a767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_1': 0, 'class_2': 1}\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.ImageFolder(root='data-mop-dog',\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(256),\n",
    "                               transforms.CenterCrop(224),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "print(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dddcb31-7961-40a1-9eaf-bc31fb6865a4",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c118755-c368-4330-95e3-1678e5312f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, weights_name='weight_save', is_inception=False):\n",
    "    print('====================== New Run =======================',file=open(f\"{weights_name}.txt\", \"a\"))\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    loss_acc_history = []\n",
    "\n",
    "    best_model_wts = deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1), file=open(f\"{weights_name}.txt\", \"a\"))\n",
    "        print('-' * 10, file=open(f\"{weights_name}.txt\", \"a\"))\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train() \n",
    "            else:\n",
    "                model.eval() \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    if is_inception and phase == 'train':\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            epoch_end = time.time()\n",
    "            \n",
    "            elapsed_epoch = epoch_end - epoch_start\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), file=open(f\"{weights_name}.txt\", \"a\"))\n",
    "            print(f\"Epoch time taken: {elapsed_epoch}\", file=open(f\"{weights_name}.txt\", \"a\"))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), weights_name + \".pth\")\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "            if phase == 'train':\n",
    "                loss_acc_history.append(epoch_loss)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60), file=open(f\"{weights_name}.txt\", \"a\"))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc), file=open(f\"{weights_name}.txt\", \"a\"))\n",
    "\n",
    "    return  val_acc_history, loss_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17140688-5fdd-44e5-9a83-d6594798236c",
   "metadata": {},
   "source": [
    "#### 1. Perform training\n",
    "\n",
    "In this part, you need to:\n",
    "- perform K-fold cross validation to get a reasonable validation accuracy estimate since you only have few examples in each category. I did for 8 folds\n",
    "- plot validation loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "793e0fef-ebaa-4d4f-848c-c67e6ab2ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your code here\n",
    "# Your Kfold\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "790b2dec-9a29-4208-8a91-94dfeeccf903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Your Plot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3251e4b4-99a2-4f41-8008-fc9a1da447a2",
   "metadata": {},
   "source": [
    "#### 2. Evaluation\n",
    "- Evaluate the model on the test samples (in data-mop-dog-test folder).\n",
    "- This includes confusion metric and displaying image along with the predicted label and its ground truth\n",
    "- Interpret the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4fb799fb-3a49-4a05-8f40-89015507ed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# transforms_function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset_test = datasets.ImageFolder(root='data-mop-dog-test',\n",
    "                           transform=transforms_function\n",
    "                           ]))\n",
    "\n",
    "#Your code here\n",
    "# data loader\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "790f9c93-33ee-4cc5-9e96-3be8662cf27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, class_names):\n",
    "    # Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), predicteds, trues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8651847d-4f65-4f36-8f6b-22f3d6929c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, predicted_labels, true_labels, class_names):\n",
    "    \"\"\"\n",
    "    Displays images with predicted and true labels.\n",
    "    \"\"\"\n",
    "    images = torchvision.utils.make_grid(images, nrow=8)  # Arrange images in a grid\n",
    "    images = images.numpy().transpose((1, 2, 0))  # Convert to (H, W, C) format\n",
    "\n",
    "    # Normalize back to [0,1] if images were normalized\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    images = std * images + mean  # Unnormalize\n",
    "    images = np.clip(images, 0, 1)  # Clip values\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(images)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Predictions: \" + \" | \".join([f\"{class_names[p]} (True: {class_names[t]})\"\n",
    "                                            for p, t in zip(predicted_labels, true_labels)]))\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    \"\"\"\n",
    "    Plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "637f5e37-38bf-465a-a8ad-665f3c570a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Evaluate & show image & confusion matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a39ca5-7bff-446b-b34d-78ca055d8607",
   "metadata": {},
   "source": [
    "## Question 3) Pretrained ResNet18 on small dataset\n",
    "\n",
    "In this question, we will train pretrained ResNet18 on the Komondor vs. Mop dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb19a402-e40f-45a2-b68c-316faa68749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0ef20fb-025a-4fe3-ba15-a17bbf7add70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Your Kfold code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca20d2e-350a-4ff1-9258-e03efd71c3ec",
   "metadata": {},
   "source": [
    "#### 2. Evaluation\n",
    "- Evaluate the model on the test samples (in data-mop-dog-test folder).\n",
    "- This includes confusion metric and displaying image along with the predicted label and its ground truth\n",
    "- Interpret the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "51dfc2c6-9f61-478a-b01a-995d1d269542",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = datasets.ImageFolder(root='data-mop-dog-test',\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(256),\n",
    "                               transforms.CenterCrop(224),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset_test,batch_size = 1,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "688fc668-ad9a-4c2b-ab60-e1a00412b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, class_names):\n",
    "    # Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), predicteds, trues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7752e82-59ce-4620-85c7-31c13c68c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Evaluate & show image & confusion matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d136a70a-484d-4e4e-ae99-149f9543fab2",
   "metadata": {},
   "source": [
    "## Question 4: Discuss the results\n",
    "You may include:\n",
    "- describe the results\n",
    "- why is it like this what are the possible reasons\n",
    "- how would y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50fe085-f6fa-4b2d-971b-ef30acf2d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
